Скорость
--------

Скорость разбора
^^^^^^^^^^^^^^^^

С pymorphy можно ожидать разбор нескольких сотен русских слов в секунду
"из коробки". После дополнительной настройки можно получить производительность в
несколько тысяч слов в секунду.

Этой скорости достаточно для многих задач (например, для различных экспериментов
и задач, связанных с web), но pymorphy в нынешнем виде, думаю, не подойдет,
если нужно быстро обрабатывать очень большие объемы данных. В этом случае
лучше использовать `lemmatizer <http://lemmatizer.org/>`_ или
`mystem <http://company.yandex.ru/technology/mystem/>`_.

У pymorphy нет цели быть быстрым, приоритет отдается качеству разбора и легкости
сопровождения. С учетом того, что это хобби-opensource-проект, код и алгоритмы
должны быть максимально простыми и понятными, чтобы облегчить внесение
изменений и доработку под конкретные задачи.

На данный момент pymorphy можно заставить работать быстрее несколькими способами:

* перейти на более быстрое хранилище (sqlite → cdb → pickle);
* отключить ненужные предсказатели;
* установить simplejson (для упрощения установки pymorphy его не требует и
  использует по умолчанию встроенный медленный модуль)::

      $ pip install simplejson

* поставить пакет `pymorphy-speedups <http://pypi.python.org/pypi/pymorphy-speedups>`_,
  который содержит авто-подключаемое Cython-расширение::

      $ pip install pymorphy-speedups

.. note::

    Для установки pymorphy-speedups и simplejson потребуются заголовочные файлы
    питона и среда с компилятором (как и для сборки любых других расширений).

Выбор хранилища для словарей
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

pymorphy поддерживает разные форматы для хранения словарей. Формат по
умолчанию - sqlite. Этот формат поддерживается везде, не требует настройки, но,
одновременно, является самым медленным.

Более быстрые альтернативы - cdb, bsddb, tcb, tch - имеют свои плюсы и минусы,
отличаются друг от друга способом установки, скоростью и потреблением памяти.

Самый быстрый вариант - это загрузка словарей целиком в память (через
pickle backend). В этом случае нет задержек на чтение данных с диска и
преобразование их в нужный формат (все читается сразу), но
расходуется 200-300Мб оперативной памяти. В этот формат словари можно
преобразовать с помощью скрипта encode_dicts.py (лежит в репозитории с исходным
кодом).

Более подробно обо всем этом можно узнать тут: :doc:`/ref/storages`.

